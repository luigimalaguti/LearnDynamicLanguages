{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analisi sintattica\n",
    "\n",
    "Rinfreschiamoci un pò la memoria.\n",
    "\n",
    "![Image 4](images/image-4.png)\n",
    "\n",
    "Abbiamo detto che generalmente lo scanner viene utilizzato come routine del parser. Quando il parse ha bisogno di token da verificare, chiama lo scanner per poterli ottenere.\n",
    "\n",
    "Abbiamo visto nel notebook precedente come lavora l'analizzatore lessicale, ovvero lo scanner. Ora analizziamo meglio il parser, colui che analizza questa volta la sintassi.\n",
    "\n",
    "Lo scopo del parser è proprio verificare se la sequenza dei token rappresentano un programma corretto dal punto di vista sintattico.\n",
    "\n",
    "> *Sintassi*  \n",
    "La sintassi è la branca della grammatica e della linguistica che studia i diversi modi in cui i codici dei linguaggi si uniscono tra loro per formare una proposizione. Nella grammatica generativa la struttura di una frase è rappresentata da alberi di struttura sintagmatica.  \n",
    "*Fonte Wikipedia*\n",
    "\n",
    "In caso di programma sintatticamente corretto, l'output del parser è una struttura nota come parse tree che costituisce l'input perr la successiva analisi semantica.  \n",
    "Allo stesso modo in cui lo scanner si occupa solamente di lessico senza entrare nel merito del possibile ordine corretto o non dei token, anche il parse si occupa solamente della sintassi, della corretta struttura delle frasi senza preoccuparsi che essa abbia o non un significato proprio o improprio.\n",
    "\n",
    "Il parser fa ampio uso di una tabella denominata ```symbol table```. Questa tabella è una struttura utilizzata sia dal frontend che dal backend del compilatore e dell'interprete. Lo scopo della symbol table è di inserire i dati relativi agli identificatori, come ad esempio: nome, tipo, posizione in memoria.\n",
    "\n",
    "Le informazioni contenenti nella symbol table vengono utilizzate dal parser per fare controlli di correttezza. In più, un'opportuna organizzazione di più symbol table consente di implementare la nozione di ambiente, namespace, con le relative regole di visibilità. Questi ultimi aspetti li considereremo più avanti.\n",
    "\n",
    "## Grammatiche libere\n",
    "\n",
    "Le grammatiche libere giocano per il parsing lo stesso ruolo che giocavano le espressioni regolari per lo scanning. Le grammatiche libere sono lo strumento che ci permette di descrivere la sintassi di un linguaggio di programmazione.\n",
    "\n",
    "In generale, una grammatica è un formalismo generativo, ovvero il linguaggio definito da una grammatica coincide con l'insieme delle stringhe generabili usando le regole che formano la grammatica stessa.\n",
    "\n",
    "## Definizione di grammatiche libere\n",
    "\n",
    "Una grammatica libera è definita da quattro elementi:\n",
    "\n",
    "- $\\mathcal{N}$, l'insieme di di simboli non terminali\n",
    "- $\\mathcal{T}$, l'insieme di simboli terminali\n",
    "- $\\mathcal{P}$, l'insieme di produzioni\n",
    "- $\\mathcal{S}$, il simbolo iniziale o assioma\n",
    "\n",
    "Quindi una grammatica $\\mathcal{G}$ è una quadrupla $\\mathcal{G} = \\left ( \\mathcal{N}, \\mathcal{T}, \\mathcal{P}, \\mathcal{S} \\right )$.\n",
    "\n",
    "Con $\\mathcal{V} = \\mathcal{N} \\cup \\mathcal{T}$ definiamo il vocabolario della grammatica.  \n",
    "La parte sinistra di una produzione viene definita testa, mentre la parte destra è detta corpo.\n",
    "\n",
    "Vediamo un semplice esempio.\n",
    "\n",
    "- $\\mathcal{N} = \\left \\{ P \\right \\}$\n",
    "- $\\mathcal{T} = \\left \\{ (,) \\right \\}$\n",
    "- $\\mathcal{S} = P$\n",
    "- $\\mathcal{P}$:\n",
    "    - $P \\rightarrow (P)P$\n",
    "    - $P \\rightarrow \\varepsilon$\n",
    "\n",
    "Il meccanismo in base al quale una grammatica genera un linguaggio è quello delle derivazioni. Una derivazione è un processo mediante il quale si ottiene una stringa di soli terminali applicado una sequenza di produzioni a partire dall'assioma. La sequenza di produzioni avviene trovando un non terminale nella frase e sostituendo la coda di essa con la produzione utilizzata. Il processo di riscrittura termina quando non sono più presenti non terminali. La forma di frase composta da soli terminali è detta frase di linguaggio.\n",
    "\n",
    "Riprendiamo l'esempio precedente.  \n",
    "Da esso abbiamo due produzioni differenti da potere applicare e quindi molte frasi di linguaggio differenti da ottenere. Questi sono due esempi: \n",
    "$$P \\stackrel{p_1} \\rightarrow (P)P \\stackrel{p_2} \\rightarrow (P) \\stackrel{p_1} \\rightarrow ((P)P) \\stackrel{p_2} \\rightarrow ((P)) \\stackrel{p_2} \\rightarrow (())$$\n",
    "$$P \\stackrel{p_1} \\rightarrow (P)P \\stackrel{p_1} \\rightarrow (P)(P)P \\stackrel{p_2} \\rightarrow (P)(P) \\stackrel{p_2} \\rightarrow (P)() \\stackrel{p_2} \\rightarrow ()()$$\n",
    "\n",
    "Il linguaggio generato da una grammatica $\\mathcal{G}$ coincide con l'insieme delle frasi derivabili dall'assioma usando le proguzioni di $\\mathcal{G}$ stesso. Solitamente si indica questo linguaggio con la seguente scrittura $L = L(\\mathcal{G})$.\n",
    "\n",
    "## Parsing\n",
    "\n",
    "Un algoritmo di parsing per un linguaggio $L(\\mathcal{G})$ è un algoritmo che data una frase generica $\\alpha$ di $L$ determina una derivazione che produce $\\alpha$ a partire dall'assioma.\n",
    "\n",
    "Un problema che può portare il processo di derivazione è il non determinismo delle frasi ottenute. Questo vuole dire che data una frase generica, non siamo in grado a priori di determinare il suo risultato anche a conoscenza di produzioni.  \n",
    "Questo succede perchè non è stata definita nessuna regola. Non è stato specificato quale sia l'ordine con cui riscrivere i non terminali, ovvero se riscrivere prima il terminale più a sinistra e poi quello successivo o l'inverso. La derivazione non ci da nessuna regola neanche riguardo l'ordine con cui utilizzare le nostre produzioni a disposizione, potremmo utilizzare una produzione invece che un'altra puramente a nostro piacimento.\n",
    "\n",
    "A fronte di questo problema di non determinismo, sono state introdotte le cosidette derivazioni canoniche, ovvero specie di linee guida per permettere di ridurre il non determinismo.  \n",
    "Le derivazioni canoniche possono essere divise in destre o sinistre. Esse ci dicono che l'ordine di derivazione dei non terminali deve avvenire a partire rispettivamente da sinistra a destra e da destra a sinistra, a seconda di derivazione canonica destra o sinistra. Tutti gli algoritmi di parsing utilizzano le derivazioni canoniche.\n",
    "\n",
    "Vediamo un esempio pratico per le derivazioni canoniche.\n",
    "\n",
    "- $\\mathcal{N} = \\left \\{ E \\right \\}$\n",
    "- $\\mathcal{T} = \\left \\{ +, \\times, (,), n \\right \\}$\n",
    "- $\\mathcal{S} = E$\n",
    "- $\\mathcal{E}$:\n",
    "    - $E \\rightarrow E + E$\n",
    "    - $E \\rightarrow E \\times E$\n",
    "    - $E \\rightarrow (E)$\n",
    "    - $E \\rightarrow n$\n",
    "\n",
    "Una generica derivazione canonica destra per una stringa £\\varepsilon_1$ può essere:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "E & \\rightarrow & E \\times E \\\\\n",
    "& \\rightarrow & E \\times E + E \\\\\n",
    "& \\rightarrow & E \\times E + n \\\\\n",
    "& \\rightarrow & E \\times n + n \\\\\n",
    "& \\rightarrow & n \\times\\ n + n\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Ma l'utilizzare le derivazioni canoniche non ci esclude totalmente il non determinismo. Infatti se cosideriamo un secondo esempio di derivazione canonica destra\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "E & \\rightarrow & E + E \\\\\n",
    "& \\rightarrow & E + n \\\\\n",
    "& \\rightarrow & E \\times E + n \\\\\n",
    "& \\rightarrow & E \\times n + n \\\\\n",
    "& \\rightarrow & n \\times\\ n + n\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Vedremo che due stringhe inizialmente differenti restituisco la stessa derivazione canonica. Quando una stessa frase frase di linguaggio è ottenibile attraverso due differenti derivazioni canoniche si dice che la grammatica è ambigua. Le grammatiche ambigue creano grossi problemi al parsing.\n",
    "\n",
    "## Alberi di derivazione\n",
    "\n",
    "Una generica derivazione la possiamo rappresentare mediante un albero, detto appunto albero di derivazione o parse tree.\n",
    "\n",
    "L'albero di derivazione rappresenta una data derivazione per una generica frase nel seguente modo:\n",
    "\n",
    "- La radice dell'albero è l'assioma della grammatica\n",
    "- Ogni nodo interno è un simbolo non terminale utilizzato nella derivazione\n",
    "- Le foglie sono i simboli terminali, che letti da sinistra a destra formano la nostra frase di linguaggio\n",
    "\n",
    "Quindi, fissato un ordine canonico, destra o sinistra, c'è una corrispondenza biunivoca tra la derivazione e il parse tree.\n",
    "\n",
    "Questa corrispondenza biunivoca tra derivazione canonica e parse tree non esclude però la presenza di ambiguità. Infatti se provassimo a scrivere le due precedenti derivazioni sottoforma di albero di derivazione\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "E & \\rightarrow & E \\times E \\\\\n",
    "& \\rightarrow & E \\times E + E \\\\\n",
    "& \\rightarrow & E \\times E + n \\\\\n",
    "& \\rightarrow & E \\times n + n \\\\\n",
    "& \\rightarrow & n \\times\\ n + n\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "![Image 6](images/image-6.png)\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "E & \\rightarrow & E + E \\\\\n",
    "& \\rightarrow & E + n \\\\\n",
    "& \\rightarrow & E \\times E + n \\\\\n",
    "& \\rightarrow & E \\times n + n \\\\\n",
    "& \\rightarrow & n \\times\\ n + n\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "![Image 7](images/image-7.png)\n",
    "\n",
    "Notiamo come risulta la corrispondenza biunivoca ma solamente tra derivazione e albero, non con la stringa iniziale.  \n",
    "Se provassimo ad utilizzare la frase ottenuta con dei valori numerici come $5 \\times 3 + 2$ ci aspettiamo che il risultato sia 17, dato che la moltiplicazione predede l'addizione. Questo ci porterebbe a dire che entrambi i parse tree alla fine dei conti possano andare bene per il nostro fine. Ma in realtà non è così.\n",
    "\n",
    "Come sappiamo il principale scopo del parsing è la verifica di correttezza sintattica, ma è altrettanto vero che il parsing deve preparare le informazioni per le fasi successive, in particolare per la generazione del codice intermedio. In questa ottica il parse tree è un elemento fondamentale.\n",
    "\n",
    "Proprio per questo motivo, possiamo dedurre che il primo albero, e quindi la prima derivazione dato la corrispondenza biunivoca, è errato. Infatti, il primo albero di derivazione suggerirebbe come prima operazione la somma tra due numeri e solo successivamente la moltiplicazione, seppur la frase risulti $n \\times n + n$. In altre parole, il primo albero conduce ad una semantica errata dell'espressione.\n",
    "\n",
    "## Grammatica non ambigua per espressioni aritmetiche\n",
    "\n",
    "L'unico modo per ottenere l'univocità delle derivazioni è scrivere una grammatica che non ammetta ambiguità. Lo scrivere grammatiche non ambigue è un lavoro molto complesso, ci sono interi studi riguardo esso. Quindi quello che possiamo fare è analizzare come una grammatica non ambigua permetta di ottenere una unica derivazione per ogni frase linguistica.\n",
    "\n",
    "La seguente grammatica risulta non ambigua per espressioni aritmetiche. Non dimostreremo la non ambiguità perchè come già detto non è un lavoro facile.\n",
    "\n",
    "- $\\mathcal{N} = \\left \\{ E, T, P, F \\right \\}$\n",
    "- $\\mathcal{T} = \\left \\{ +, -, \\times, /, ^, (,), n \\right \\}$\n",
    "- $\\mathcal{S} = E$\n",
    "- $\\mathcal{E}$:\n",
    "    - $E \\rightarrow E + T | E - T | T$\n",
    "    - $T \\rightarrow T \\times P | T / P | P$\n",
    "    - $P \\rightarrow F ^ P | F$\n",
    "    - $F \\rightarrow n | (E)$\n",
    "\n",
    "Il simbolo $|$ che compare nella definizione della grammatica è un metasimbolo proprio come $\\rightarrow$, il significato di esso è sostanzialmente l'OR logico, ovvero una produzione per $E$ può essere $E \\rightarrow E + T$ o $E \\rightarrow E - T$ o $E \\rightarrow T$.\n",
    "\n",
    "Detto ciò possiamo utilizzare queste produzioni per cercare di ottenere lo stesso risultato precedente: $n \\times n + n$. Questa di seguito è l'unica derivazione canonica destra possibile per la frase in questione.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "E & \\rightarrow & E + T \\\\\n",
    "& \\rightarrow & E + P \\\\\n",
    "& \\rightarrow & E + F \\\\\n",
    "& \\rightarrow & E + n \\\\\n",
    "& \\rightarrow & T + n \\\\\n",
    "& \\rightarrow & T \\times P + n \\\\\n",
    "& \\rightarrow & T \\times F + n \\\\\n",
    "& \\rightarrow & T \\times n + n \\\\\n",
    "& \\rightarrow & P \\times n + n \\\\\n",
    "& \\rightarrow & F \\times n + n \\\\\n",
    "& \\rightarrow & n \\times n + n \\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Il procedimento da svolgere per ottenere questa derivazione consiste sostanzialmente di tentare determinate produzioni finchè non si ottiene una frase di soli non terminali. Quando utilizzeremo produzioni \"sbagliate\" per il nostro scopo, arriveremo ad un punto che non potremmo fare altro che tornare indietro di un passo per tentare una produzione differente. Questo lo si svolge finchè non si arriva alla unica soluzione.\n",
    "\n",
    "Il parse tree della derivazione canonica destra è il seguente.\n",
    "\n",
    "![Image 8](images/image-8.png)\n",
    "\n",
    "## Abstract syntaxt tree\n",
    "\n",
    "Gli AST per un linguaggio $L$ è un albero in cui:\n",
    "\n",
    "- I nodi interni rappresentano i costrutti di $L$\n",
    "- Le foglie sono token, in genere con riferimento alla symbol table\n",
    "\n",
    "L'abstract syntaxt tree dell'esempio che abbiamo analizzato precedentemente è il seguente.\n",
    "\n",
    "![Image 9](images/image-9.png)\n",
    "\n",
    "Una volta che otteniamo l'AST, la generazione di codice intermedio è un esercizio abbastanza semplice. Il problema però è che dobbiamo trovare il modo di ottenere l'AST.\n",
    "\n",
    "## Parsing bottom up\n",
    "\n",
    "Il parser bottom up procede nel modo inverso a quanto visto fino ad adesso. Il parser bottom up parte dalla stringa da riconoscere fino ad arrivare all'assioma iniziale. Il parser quindi tenta di ricostruire a rovescio la descrizione canonica destra a partire dalla frase e per fare ciò deve quindi applicare le produzioni nel senso opposto, body to head. Solitamente si usa dire che una produzione applicata in questo modo è una riduzione.\n",
    "\n",
    "Analizziamo il parser bottom up sull'esempio che portiamo avanti da quasi tutto il notebook. Per maggiore chiarezza chiamiamo ogni simbolo con un relatico pedice per distinguerli.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "E_1 & \\rightarrow & E_2 + T_1 \\\\\n",
    "& \\rightarrow & E_2 + P_1 \\\\\n",
    "& \\rightarrow & E_2 + F_1 \\\\\n",
    "& \\rightarrow & E_2 + n_1 \\\\\n",
    "& \\rightarrow & T_2 + n_1 \\\\\n",
    "& \\rightarrow & T_3 \\times P_2 + n_1 \\\\\n",
    "& \\rightarrow & T_3 \\times F_2 + n_1 \\\\\n",
    "& \\rightarrow & T_3 \\times n_2 + n_1 \\\\\n",
    "& \\rightarrow & P_3 \\times n_2 + n_1 \\\\\n",
    "& \\rightarrow & F_3 \\times n_2 + n_1 \\\\\n",
    "& \\rightarrow & n_3 \\times n_2 + n_1 \\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Il parse svolge questi tre passi:\n",
    "\n",
    "1. Recupera un simbolo terminale dall'input e lo inserisce nello stack, operazione detta ```shift```\n",
    "2. Individua sulla cima dello stack la parte destra di una produzione e ne sostituisce tutti i simboli con la relativa parte sinistra, operazione di ```reduce```\n",
    "3. Infine ```accetta``` o ```rifiuta``` l'input come appartenente o non appartenente al linguaggio"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\\begin{array}{lclcrcl}\n",
    "\\mathrm{step}&&\\mathrm{stack}&&\\mathrm{input}&&\\mathrm{action} \\\\\n",
    "1 && \\$ && n_3 \\times n_2 + n_1\\$ && shift \\\\\n",
    "2 && \\$n_3 && \\times n_2 + n_1\\$ && reduce \\ by \\ F \\rightarrow n \\\\\n",
    "3 && \\$F_3 && \\times n_2 + n_1\\$ && reduce \\ by \\ P \\rightarrow F \\\\\n",
    "4 && \\$P_3 && \\times n_2 + n_1\\$ && reduce \\ by \\ T \\rightarrow P \\\\\n",
    "5 && \\$T_3 && \\times n_2 + n_1\\$ && shift \\\\\n",
    "6 && \\$T_3 \\times && n_2 + n_1\\$ && shift \\\\\n",
    "7 && \\$T_3 \\times n_2 && + n_1\\$ && reduce \\ by \\ F \\rightarrow n \\\\\n",
    "8 && \\$T_3 \\times F_2 && + n_1\\$ && reduce \\ by \\ P \\rightarrow F \\\\\n",
    "9 && \\$T_3 \\times P_2 && + n_1\\$ && reduce \\ by \\ T \\rightarrow T \\times P \\\\\n",
    "10 && \\$T_2 && + n_1\\$ && reduce \\ by \\ E \\rightarrow T \\\\\n",
    "11 && \\$E_2 && + n_1\\$ && shift \\\\\n",
    "12 && \\$E_2 + && n_1\\$ && shift \\\\\n",
    "13 && \\$E_2 + n_1 && \\$ && reduce \\ by \\ F \\rightarrow n \\\\\n",
    "14 && \\$E_2 + F_1 && \\$ && reduce \\ by \\ P \\rightarrow F \\\\\n",
    "15 && \\$E_2 + P_1 && \\$ && reduce \\ by \\ T \\rightarrow P \\\\\n",
    "16 && \\$E_2 + T_1 && \\$ && reduce \\ by \\ E \\rightarrow E + T \\\\\n",
    "17 && \\$E_1 && \\$ && accept\n",
    "\\end{array}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Risulta abbastanza evidente come la descrizione del funzionamento del parser non sia un algoritmo. Infatti persistono elementi di non determinismo, nello specifico due casi particolari:\n",
    "\n",
    "- Quando è possibile applicare sia una riduzione che uno shift\n",
    "- Quando sulla cima dello stack è presente la parte destra di più di una produzione\n",
    "\n",
    "Non entriamo nei dettagli di come vengono gestiti questi casi particolari perchè sarà proprio il parser a occuparsene. Quanto visto fino ad adesso è sufficiente a comprendere il modo di utilizzare tale strumento. Va però precisato che non tutte le grammatiche sono adatte a tutti gli strumenti. Noi utilizzeremo ```ply.yacc```.\n",
    "\n",
    "## Generatori di parser\n",
    "\n",
    "Ora, come fatto per lo scanner, andremo a generare un interprete per le espressioni aritmetiche definite dalla grammatica non ambigua definita precedentemente. Ciò comporta la scrittura anche di uno scanner specifico per il nostro scopo, oltre che il parser.\n",
    "\n",
    "Andremo ad utilizzare sempre il modulo python ```ply.lex``` per lo scanner, mentre il modulo ```ply.yacc``` per il parser."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ply import lex\n",
    "from ply import yacc"
   ]
  },
  {
   "source": [
    "Questo sarà il nostro scanner."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ('NUMBER','PLUS','MINUS','MUL','DIV','POW','LPAR','RPAR',)\n",
    "\n",
    "t_PLUS  = r'\\+'\n",
    "t_MINUS = r'-'\n",
    "t_MUL   = r'\\*'\n",
    "t_DIV   = r'/'\n",
    "t_POW   = r'\\^'          \n",
    "t_LPAR  = r'\\('\n",
    "t_RPAR  = r'\\)'\n",
    "\n",
    "def t_NUMBER(t):\n",
    "    r'\\d+'\n",
    "    t.value = int(t.value)\n",
    "    return t\n",
    " \n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += len(t.value)\n",
    "\n",
    "t_ignore  = r' \\t'\n",
    "\n",
    "def t_error(t):\n",
    "    print(f\"Illegal character {t.value[0]}\")\n",
    "    t.lexer.skip(1)\n",
    "\n",
    "lexer = lex.lex()"
   ]
  },
  {
   "source": [
    "Yacc è l'acronimo di ```Yet Another Compiler Compiler```. È uno strumento di ausilio alla generazione di compilatori a partire dalla definizione della grammatica. Un meccanismo simile allo scanner. Si tratta di un complemento di lex, infatti tipicamente yacc importa i token definiti in lex."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('NUMBER', 'PLUS', 'MINUS', 'MUL', 'DIV', 'POW', 'LPAR', 'RPAR')\n"
     ]
    }
   ],
   "source": [
    "from codes.expressions_scanner import tokens\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "source": [
    "Le produzioni e le corrispondenti azioni che devono essere eseguite dal parser le forniamo come funzioni, in particolare, come anche nello scanner, utilizziamo la docstring della funzoine stessa per indicare la produzione relativa. Il corpo della funzione contiene invece il codice che deve essere eseguito nel momento in cui la produzione viene utilizzata per la riduzione.\n",
    "\n",
    "La nomenclatura delle funzioni è analoga a quella dello scanner tranne per la lettera t."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_expression_add(p):\n",
    "    'expression : expression PLUS term'\n",
    "    p[0] = p[1] + p[3]\n",
    "\n",
    "def p_expression_sub(p):\n",
    "    'expression : expression MINUS term'\n",
    "    p[0] = p[1] - p[3]\n",
    "\n",
    "def p_expression_term(p):\n",
    "    'expression : term'\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_term_mul(p):\n",
    "    'term : term MUL power'\n",
    "    p[0] = p[1] * p[3]\n",
    "\n",
    "def p_term_div(p):\n",
    "    'term : term DIV power'\n",
    "    p[0] = p[1] // p[3]\n",
    "\n",
    "def p_term_power(p):\n",
    "    'term : power'\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_power_raise(p):\n",
    "    'power : factor POW power'\n",
    "    p[0] = p[1] ** p[3]\n",
    "    \n",
    "def p_power_factor(p):\n",
    "    'power : factor'\n",
    "    p[0] = p[1]\n",
    "    \n",
    "def p_factor_num(p):\n",
    "    'factor : NUMBER'\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_factor_expr(p):\n",
    "    'factor : LPAR expression RPAR'\n",
    "    p[0] = p[2]\n",
    "\n",
    "def p_error(p):\n",
    "    print(\"Syntax error in input!\")"
   ]
  },
  {
   "source": [
    "Il parser utilizza una lista per ottenere i token relativi ad una riduzione, ogni simbolo corrisponde ad un indice nella lista stessa. Tantè che nelle definizioni delle funzioni quello che noi intendiamo come operatore, ad esempio ```+```, viene saltato come indice perche lo sostituiamo il suo effettivo significato, utilizzando solamente gli indici corrispondenti ai token veri e propri.\n",
    "\n",
    "Vediamo ora un possibile main program per l'utilizzo di quanto fatto fino ad ora."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = yacc.yacc()\n",
    "    while True:\n",
    "        try:\n",
    "            s = input('calc (ctrl-d to quit) > ')\n",
    "        except EOFError:\n",
    "            break\n",
    "        if not s: continue\n",
    "        result = parser.parse(s)\n",
    "        print(result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "source": [
    "Ovviamente tutti i file relativi a questo esempio li ho inseriti nella cartella ```codes``` nominati rispettivamente ```expressions_scanner```, ```expressions_parser```, ```expressions_main```.\n",
    "\n",
    "L'esecuzione non avviene tramite IPython per lo stesso modivo spiegato nel notebook dello scanner. Per eseguire il codice di esempio ci basta utilizzare il seguente comando:\n",
    "\n",
    "```\n",
    "python expressions_main.py\n",
    "```\n",
    "\n",
    "E inserire l'espressione di cui vogliamo il risultato:\n",
    "\n",
    "```\n",
    "calc (ctrl-d to quit) > 5*3/2\n",
    "17\n",
    "```\n",
    "\n",
    "Nel caso volessimo arricchire il parser con ulteriori produzioni, come la seguente:\n",
    "\n",
    "- $\\mathcal{N} = \\left \\{ E, T, P, F \\right \\}$\n",
    "- $\\mathcal{T} = \\left \\{ +, -, \\times, /, ^, (,), n \\right \\}$\n",
    "- $\\mathcal{S} = E$\n",
    "- $\\mathcal{E}$:\n",
    "    - $E \\rightarrow E + T | E - T | T$\n",
    "    - $T \\rightarrow T \\times P | T / P | P$\n",
    "    - $P \\rightarrow F ^ P | F$\n",
    "    - $F \\rightarrow pi | sqrt(E) | n | (E)$\n",
    "\n",
    "Ci basterebbe aggiungere le relative produzioni nel file del parser con le seguenti funzioni:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi, sqrt\n",
    "\n",
    "def p_factor_pi(p):\n",
    "    'factor : PI'\n",
    "    p[0] = pi\n",
    "    \n",
    "def p_factor_sqrt(p):\n",
    "    'factor : SQRT LPAR expression RPAR'\n",
    "    p[0] = sqrt(p[3])\n",
    "\n",
    "# Non può più essere una divisione intera\n",
    "def p_term_div(p):\n",
    "    'term : term DIV power'\n",
    "    p[0] = p[1] / p[3]"
   ]
  },
  {
   "source": [
    "E aggiungere nello scanner i token necessari:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens += ('SQRT','PI')\n",
    "\n",
    "def t_SQRT(t):\n",
    "    r'sqrt\\b'\n",
    "    return t\n",
    "\n",
    "def t_PI(t):\n",
    "    r'pi\\b'\n",
    "    return t\n",
    "\n",
    "def t_NUMBER(t):\n",
    "    r'[1-9]+[.]?\\d*|[0]?\\.\\d+'\n",
    "    return t"
   ]
  }
 ]
}